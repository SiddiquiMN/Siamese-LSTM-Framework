{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGO1sNNdLJbpKRBQPrUZQ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qO6SK4YFq-SV","executionInfo":{"status":"ok","timestamp":1714164626001,"user_tz":-360,"elapsed":30768,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"6948bf0a-976e-4f79-9271-26e6e6dc1c25"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define the path to the CSV file\n","csv_path = '/content/drive/MyDrive/CSV Files/DATASET SUPREMACY.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","df = pd.read_csv(csv_path)\n","\n","# Select only the last column\n","last_column = df.iloc[:, -1]\n","\n","# Define the path for the new CSV file to be saved\n","new_csv_path = '/content/drive/MyDrive/CSV Files/last_column.csv'\n","\n","# Save the last column to a new CSV file\n","last_column.to_csv(new_csv_path, index=False)\n","\n","print(\"Last column saved to:\", new_csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5JWMP-PLHGc","executionInfo":{"status":"ok","timestamp":1714164638121,"user_tz":-360,"elapsed":1861,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"d6fc3c7e-b8f5-4e9e-da4f-585cf049140e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Last column saved to: /content/drive/MyDrive/CSV Files/last_column.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the last column CSV file into a pandas DataFrame\n","last_column_df = pd.read_csv('/content/drive/MyDrive/CSV Files/last_column.csv')\n","\n","# Define the column names\n","columns = ['2000-2005', '2005-2010', '2010-2015', '2015-2020']\n","\n","# Initialize a dictionary to store data for the new DataFrame\n","data = {col: [] for col in columns}\n","\n","# Iterate over the values in the last column and distribute them across the columns\n","num_values = len(last_column_df)\n","for i, value in enumerate(last_column_df.iloc[:, 0]):\n","    col_index = i % len(columns)  # Calculate the index of the column to put the value in\n","    data[columns[col_index]].append(value)\n","\n","# Create a new DataFrame from the data dictionary\n","new_df = pd.DataFrame(data)\n","\n","# Define the path for the new CSV file to be saved\n","new_csv_path = '/content/drive/MyDrive/CSV Files/gvidiff_yearwise.csv'\n","\n","# Save the new DataFrame to a CSV file\n","new_df.to_csv(new_csv_path, index=False)\n","\n","print(\"Data distributed across columns and saved to:\", new_csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmLAo7GDL38g","executionInfo":{"status":"ok","timestamp":1714165083628,"user_tz":-360,"elapsed":8,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"48aa1ce8-31e3-4646-f0c1-14cbabf4dacf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Data distributed across columns and saved to: /content/drive/MyDrive/CSV Files/gvidiff_yearwise.csv\n"]}]},{"cell_type":"markdown","source":["**SARIMA**"],"metadata":{"id":"BnB2h4TpU15W"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWN4-tCIq7EW","executionInfo":{"status":"ok","timestamp":1714165159809,"user_tz":-360,"elapsed":2771,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"1ba6d5a6-5f8c-47cb-d32b-c641c5d49fae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 7.7564943351048115\n","Test MSE: 107.17839942095479\n","Test RMSE: 10.352700102917828\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# Load and prepare data (replace with your file path)\n","data = pd.read_csv(\"/content/drive/MyDrive/CSV Files/gvidiff_yearwise.csv\")\n","\n","# Extract the relevant columns\n","dataset = data[['2000-2005', '2005-2010', '2010-2015', '2015-2020']]\n","\n","# Split data into training and testing sets\n","training_data = dataset.iloc[:int(0.7 * len(dataset))]\n","testing_data = dataset.iloc[int(0.7 * len(dataset)):]\n","\n","# Define the SARIMA model\n","order = (1, 1, 1)\n","seasonal_order = (1, 1, 1, 12)  # Define seasonal_order parameter (P, D, Q, S)\n","\n","# Fit the SARIMA model\n","model = SARIMAX(training_data['2015-D2020'], order=order, seasonal_order=seasonal_order)\n","results = model.fit()\n","\n","forecast = results.forecast(steps=len(testing_data))\n","\n","y_true = testing_data['2015-2020']\n","mae = mean_absolute_error(y_true, forecast)\n","mse = mean_squared_error(y_true, forecast)\n","rmse = np.sqrt(mse)\n","\n","# Print evaluation metrics\n","print(\"Test MAE:\", mae)\n","print(\"Test MSE:\", mse)\n","print(\"Test RMSE:\", rmse)\n"]}]}