{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPmMkDC9EE8YbAuRzRVAD92"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2aXtiT1Wg6T5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697046434319,"user_tz":-360,"elapsed":50016,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"1fbf7da8-ade6-4b8a-95d7-52e904616e2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Seperating area names from images and storing images as seperate years. We are working on forest dataset. This code may not work for other category dataset."],"metadata":{"id":"X8rCSE_KKjTg"}},{"cell_type":"code","source":["import os\n","from collections import defaultdict\n","from PIL import Image\n","import re\n","\n","# Path to the folder containing the images\n","folder_path = '/content/drive/MyDrive/Sowmik Dataset/Planned_way/Forest all processed file/Preprocessed forest'\n","\n","# Initialize dictionaries to store images based on year and area\n","image_arrays = defaultdict(lambda: defaultdict(list))\n","\n","# List of valid years\n","valid_years = ['2000', '2005', '2010', '2015', '2020']\n","\n","# Iterate through files in the folder and determine area names\n","area_names = set()\n","iteration_count = 0\n","\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.jpg'):\n","        # Try extracting the area name using '-' and ' '\n","        parts = re.split(r'[-\\s]', filename)\n","        #area_name = parts[0].strip().split('–')[0]\n","\n","\n","        # Take only the first part of the area name and remove any characters after space or '-'\n","        #area_name = re.sub(r'[^\\w\\s]', '', parts[0].strip())\n","        area_name = parts[0].strip().split('–')[0]\n","\n","        # Check if the extracted area name is valid (not a number and doesn't contain '.jpg')\n","        if area_name and not area_name.isdigit() and '.jpg' not in area_name and not area_name.startswith(' '):\n","            area_names.add(area_name)\n","\n","            # Increment the iteration count and determine the year\n","            iteration_count += 1\n","            year_index = (iteration_count - 1) % len(valid_years)\n","            year = valid_years[year_index]\n","\n","            # Load the image and append to the respective array based on year and area\n","            image_path = os.path.join(folder_path, filename)\n","            image = Image.open(image_path)\n","            image_arrays[year][area_name].append(image)\n","\n","# Print the extracted area names\n","print(\"Extracted Area Names:\", area_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABmBVApfMHHy","executionInfo":{"status":"ok","timestamp":1697053587749,"user_tz":-360,"elapsed":18,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"3a0b5d0a-83aa-47b8-97b9-41fe7fd1eeb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Area Names: {'Macky', 'Echuca', 'Mildura', 'Zigzag', 'Armidale', 'Fox', 'Goulburn', 'Alto', 'MVP', 'Gisborne', 'Cyril'}\n"]}]},{"cell_type":"code","source":["area_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6s3xilaF8P-G","executionInfo":{"status":"ok","timestamp":1697052913437,"user_tz":-360,"elapsed":15,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"ae1d9d11-7e0e-481d-ced7-ce8a9bfe30cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Alto',\n"," 'Armidale',\n"," 'Cyril',\n"," 'Echuca',\n"," 'Fox',\n"," 'Gisborne',\n"," 'Goulburn',\n"," 'MVP',\n"," 'Macky',\n"," 'Mildura',\n"," 'Zigzag'}"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["Making pairs of\n","2020 - 2000\n","2020 - 2005\n","2020 - 2010\n","2020 - 2015"],"metadata":{"id":"BQim1GTeKrYm"}},{"cell_type":"code","source":["# Define the target years for pairing\n","target_years = ['2000', '2005', '2010', '2015']\n","\n","# Initialize a dictionary to store pairs for each area\n","area_pairs = {area: [] for area in area_names}\n","\n","# Iterate through each area and create pairs\n","for area in area_names:\n","    # Get the image for the current year (2020)\n","    current_year_images = image_arrays['2020'][area]\n","    current_area_image = current_year_images[0]\n","\n","    # Iterate through the target years and create pairs for the current area\n","    for target_year in target_years:\n","        # Find the image for the target year\n","        target_year_images = image_arrays[target_year][area]\n","        target_area_image = target_year_images[0]\n","\n","        # Add the pair of images to the respective area\n","        area_pairs[area].append((current_area_image, target_area_image))\n","\n","# Print the pairs for each area\n","for area, pairs in area_pairs.items():\n","    print(f\"Pairs for {area}:\")\n","    for i, (current_image, target_image) in enumerate(pairs):\n","        print(f\"Pair {i+1}: {area} 2020 - {area} {target_years[i]}\")\n","\n","\n","\n","# Now area_pairs contains pairs of images for each area and the specified years\n","# Access the pairs using area_pairs['area1'], area_pairs['area2'], etc.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgHb71h33xOf","executionInfo":{"status":"ok","timestamp":1697053591994,"user_tz":-360,"elapsed":15,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"0f552b6d-ff0e-4567-b22a-c8edd9568cb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pairs for Macky:\n","Pair 1: Macky 2020 - Macky 2000\n","Pair 2: Macky 2020 - Macky 2005\n","Pair 3: Macky 2020 - Macky 2010\n","Pair 4: Macky 2020 - Macky 2015\n","Pairs for Echuca:\n","Pair 1: Echuca 2020 - Echuca 2000\n","Pair 2: Echuca 2020 - Echuca 2005\n","Pair 3: Echuca 2020 - Echuca 2010\n","Pair 4: Echuca 2020 - Echuca 2015\n","Pairs for Mildura:\n","Pair 1: Mildura 2020 - Mildura 2000\n","Pair 2: Mildura 2020 - Mildura 2005\n","Pair 3: Mildura 2020 - Mildura 2010\n","Pair 4: Mildura 2020 - Mildura 2015\n","Pairs for Zigzag:\n","Pair 1: Zigzag 2020 - Zigzag 2000\n","Pair 2: Zigzag 2020 - Zigzag 2005\n","Pair 3: Zigzag 2020 - Zigzag 2010\n","Pair 4: Zigzag 2020 - Zigzag 2015\n","Pairs for Armidale:\n","Pair 1: Armidale 2020 - Armidale 2000\n","Pair 2: Armidale 2020 - Armidale 2005\n","Pair 3: Armidale 2020 - Armidale 2010\n","Pair 4: Armidale 2020 - Armidale 2015\n","Pairs for Fox:\n","Pair 1: Fox 2020 - Fox 2000\n","Pair 2: Fox 2020 - Fox 2005\n","Pair 3: Fox 2020 - Fox 2010\n","Pair 4: Fox 2020 - Fox 2015\n","Pairs for Goulburn:\n","Pair 1: Goulburn 2020 - Goulburn 2000\n","Pair 2: Goulburn 2020 - Goulburn 2005\n","Pair 3: Goulburn 2020 - Goulburn 2010\n","Pair 4: Goulburn 2020 - Goulburn 2015\n","Pairs for Alto:\n","Pair 1: Alto 2020 - Alto 2000\n","Pair 2: Alto 2020 - Alto 2005\n","Pair 3: Alto 2020 - Alto 2010\n","Pair 4: Alto 2020 - Alto 2015\n","Pairs for MVP:\n","Pair 1: MVP 2020 - MVP 2000\n","Pair 2: MVP 2020 - MVP 2005\n","Pair 3: MVP 2020 - MVP 2010\n","Pair 4: MVP 2020 - MVP 2015\n","Pairs for Gisborne:\n","Pair 1: Gisborne 2020 - Gisborne 2000\n","Pair 2: Gisborne 2020 - Gisborne 2005\n","Pair 3: Gisborne 2020 - Gisborne 2010\n","Pair 4: Gisborne 2020 - Gisborne 2015\n","Pairs for Cyril:\n","Pair 1: Cyril 2020 - Cyril 2000\n","Pair 2: Cyril 2020 - Cyril 2005\n","Pair 3: Cyril 2020 - Cyril 2010\n","Pair 4: Cyril 2020 - Cyril 2015\n"]}]},{"cell_type":"markdown","source":["Seperate area name from binary mask and extracting years"],"metadata":{"id":"DoAbj5xWK457"}},{"cell_type":"code","source":["import os\n","from collections import defaultdict\n","from PIL import Image\n","import re\n","\n","# Path to the folder containing the images\n","folder_path = '/content/drive/MyDrive/Sowmik Dataset/Planned_way/Forest all processed file/Preprocessed forest/bmask_forest'\n","\n","# Initialize dictionaries to store images based on year and area\n","mask_image_arrays = defaultdict(lambda: defaultdict(list))\n","\n","# List of valid years\n","mask_valid_years = ['2000', '2005', '2010', '2015', '2020']\n","\n","# Extract area names in the desired format\n","mask_area_names = set()\n","iteration_count = 0\n","\n","for filename in os.listdir(folder_path):\n","    if filename.startswith('pp_') and filename.endswith('_mask.jpg'):\n","        # Exclude the prefix and suffix from the filename and extract the area name\n","        area_name = filename[3:-9]  # Exclude 'pp_' (3 characters) and '_mask.jpg' (9 characters)\n","\n","        # Extract only the first part of the name up to the first hyphen '-' or space ' '\n","        area_name_parts = re.split(r'[-\\s]', area_name)\n","        area_name = area_name_parts[0].strip() if area_name_parts[0].strip() else ''  # Take the first part\n","\n","        # Check if the extracted area name is valid (not empty)\n","        if area_name:\n","            # Remove any remaining hyphens from the first part\n","            area_name = area_name.split('-')[0].strip()\n","\n","            # Remove any remaining hyphens from the first part\n","            area_name = area_name.split('–')[0].strip()\n","\n","            # Add the modified area name to the set\n","            mask_area_names.add(area_name)\n","\n","            # Increment the iteration count and determine the year\n","            iteration_count += 1\n","            year_index = (iteration_count - 1) % len(mask_valid_years)\n","            year = mask_valid_years[year_index]\n","\n","            # Load the image and append to the respective array based on year and area\n","            image_path = os.path.join(folder_path, filename)\n","            image = Image.open(image_path)\n","            mask_image_arrays[year][area_name].append(image)\n","\n","# Print the extracted area names and years\n","print(\"Extracted Area Names:\", mask_area_names)\n","print(\"Extracted Years:\", mask_valid_years)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhkARMSnQerI","executionInfo":{"status":"ok","timestamp":1697053276536,"user_tz":-360,"elapsed":448,"user":{"displayName":"thesis research","userId":"06634674941398765871"}},"outputId":"d0465e67-ac51-4cfe-9fe6-98813aba7f4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Area Names: {'Macky', 'Echuca', 'Mildura', 'Zigzag', 'Armidale', 'Fox', 'Goulburn', 'Alto', 'MVP', 'Gisborne', 'Cyril'}\n","Extracted Years: ['2000', '2005', '2010', '2015', '2020']\n"]}]},{"cell_type":"markdown","source":["Now I have\n","\n","\n","1.    area_names\n","2.   valid_years\n","3.  mask_area_names\n","4. mask_valid_years\n","5. area_pairs (for raw image)\n","**why did we extract name and year twice for raw image and binary mask?? we could just directly extract from binary masks!!**\n","\n","Next task is to\n","\n","1.   Calculate GVI of each image (using binary image)\n","2. Pair image\n","3. Store their GVI difference\n","\n","\n","\n"],"metadata":{"id":"h5yiFMGXQiDP"}},{"cell_type":"markdown","source":[],"metadata":{"id":"GWWVbHbub2mD"}},{"cell_type":"code","source":["def calculate_gvi(binary_image):\n","    # Count the number of white pixels (vegetation) in the binary image\n","    white_pixels = (binary_image == 255).sum()\n","\n","    # Count the total number of pixels in the image\n","    total_pixels = binary_image.size\n","\n","    # Calculate the GVI value (percentage of vegetation)\n","    gvi_value = (white_pixels / total_pixels) * 100\n","\n","    return gvi_value\n","\n","\n","def calculate_gvi_difference(image_1, image_2):\n","    gvi_1 = calculate_gvi(image_1)\n","    gvi_2 = calculate_gvi(image_2)\n","    gvi_difference = gvi_2 - gvi_1\n","    return gvi_difference\n","\n"],"metadata":{"id":"0UeuoehRQjBz"},"execution_count":null,"outputs":[]}]}